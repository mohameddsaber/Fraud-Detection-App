# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10_k1N2GQClPr-NTSt3X6PAvkjAfl9foQ
"""

import tkinter as tk
from tkinter import filedialog
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
from matplotlib import pyplot as plt
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

class FraudDetectionApp(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("Fraud Detection App")
        self.geometry("600x400")

        self.train_label = tk.Label(self, text="Select Training Dataset:")
        self.train_label.pack(pady=10)

        self.train_button = tk.Button(self, text="Select", command=self.select_train_data)
        self.train_button.pack()

        self.test_label = tk.Label(self, text="Select Testing Dataset:")
        self.test_label.pack(pady=10)

        self.test_button = tk.Button(self, text="Select", command=self.select_test_data)
        self.test_button.pack()

        self.run_rf_button = tk.Button(self, text="Run Random Forest", command=self.run_rf_model)
        self.run_rf_button.pack()

        self.run_gb_button = tk.Button(self, text="Run Gradient Boosting", command=self.run_gb_model)
        self.run_gb_button.pack()

        self.run_xgb_button = tk.Button(self, text="Run XGBoost", command=self.run_xgb_model)
        self.run_xgb_button.pack()

        self.run_knn_button = tk.Button(self, text="Run KNN", command=self.run_knn_model)
        self.run_knn_button.pack()

        self.class_labels = ["not fraud", "fraud"]

    def select_train_data(self):
        self.train_file_path = filedialog.askopenfilename(title="Select Training Dataset",
                                                          filetypes=(("CSV files", "*.csv"),))
        self.train_label.configure(text=f"Selected Training Dataset: {self.train_file_path}")

    def select_test_data(self):
        self.test_file_path = filedialog.askopenfilename(title="Select Testing Dataset",
                                                         filetypes=(("Excel files", "*.xlsx"),))
        self.test_label.configure(text=f"Selected Testing Dataset: {self.test_file_path}")

    def load_and_preprocess_data(self):
        train_df = pd.read_csv(self.train_file_path)
        test_df = pd.read_excel(self.test_file_path)

        train_df.dropna(inplace=True)
        test_df.dropna(inplace=True)

        def engineer_features(df):
            df['Time'] = pd.to_datetime(df['Time'])
            df['Hour'] = df['Time'].dt.hour
            df['DayOfWeek'] = df['Time'].dt.dayofweek

            df_sorted = df.sort_values(by=['Card Number', 'Time'])
            df_sorted['Time_Diff_Prev_Trans'] = df_sorted.groupby('Card Number')['Time'].diff().dt.total_seconds().fillna(0)
            df_sorted['Amount_Diff_Avg'] = df_sorted['Amount'] - df_sorted.groupby('Card Number')['Amount'].transform('mean')
            df_sorted['Transactions_Last_Hour'] = df_sorted.groupby('Card Number')['Time'].diff().lt(pd.Timedelta(hours=1)).astype(int).cumsum()
            df_sorted['Amount_Diff_Median'] = df_sorted['Amount'] - df_sorted.groupby('Card Number')['Amount'].transform('median')

            df = pd.concat([df, df_sorted[['Time_Diff_Prev_Trans', 'Amount_Diff_Avg', 'Transactions_Last_Hour', 'Amount_Diff_Median']]], axis=1)
            return df

        train_df = engineer_features(train_df)
        test_df = engineer_features(test_df)

        scaler = StandardScaler()
        train_df['Amount'] = scaler.fit_transform(train_df[['Amount']])
        test_df['Amount'] = scaler.transform(test_df[['Amount']])

        columns_to_scale = ['Time_Diff_Prev_Trans', 'Transactions_Last_Hour']
        train_df[columns_to_scale] = scaler.fit_transform(train_df[columns_to_scale])
        test_df[columns_to_scale] = scaler.transform(test_df[columns_to_scale])

        combined_df = pd.concat([train_df, test_df], axis=0)
        lbl = LabelEncoder()
        combined_df['merchant'] = lbl.fit_transform(combined_df['merchant'])
        combined_df['category'] = lbl.fit_transform(combined_df['category'])

        train_df = combined_df.iloc[:len(train_df)]
        test_df = combined_df.iloc[len(train_df):]

        fraud = train_df[train_df['is_fraud'] == 1]
        legit = train_df[train_df['is_fraud'] == 0]

        us_legit = legit.sample(n=500000, random_state=42)
        us_train = pd.concat([fraud, us_legit])
        us_train = us_train.sample(frac=1, random_state=42).reset_index(drop=True)

        train_split = us_train[:450000]
        val_split = us_train[450000:]
        test_split = test_df.sample(n=50000, random_state=42)

        features = ['Amount', 'merchant', 'category', 'Hour', 'DayOfWeek', 'Time_Diff_Prev_Trans', 'Transactions_Last_Hour', 'Amount_Diff_Median', 'Amount_Diff_Avg']
        x_train_split = train_split[features]
        y_train_split = train_split['is_fraud']
        x_val_split = val_split[features]
        y_val_split = val_split['is_fraud']
        x_test = test_split[features]
        y_test = test_split['is_fraud']

        return x_train_split, x_val_split, y_train_split, y_val_split, x_test, y_test

    def evaluate_model(self, model, x_val_split, y_val_split, x_test, y_test):
        y_val_pred = model.predict(x_val_split)
        y_test_pred = model.predict(x_test)

        print("Validation Accuracy:", accuracy_score(y_val_split, y_val_pred))
        print("Test Accuracy:", accuracy_score(y_test, y_test_pred))
        print("Classification Report:\n", classification_report(y_test, y_test_pred, target_names=self.class_labels))
        print("Confusion Matrix:\n", confusion_matrix(y_test, y_test_pred))

        sns.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, fmt="d", cmap="Blues", xticklabels=self.class_labels, yticklabels=self.class_labels)
        plt.xlabel("Predicted")
        plt.ylabel("Truth")
        plt.title("Confusion Matrix")
        plt.show()

    def run_rf_model(self):
        x_train_split, x_val_split, y_train_split, y_val_split, x_test, y_test = self.load_and_preprocess_data()

        rf = RandomForestClassifier(n_estimators=99,
                                    criterion='gini',
                                    min_samples_split=4,
                                    min_samples_leaf=3,
                                    random_state=42)
        rf.fit(x_train_split, y_train_split)

        self.evaluate_model(rf, x_val_split, y_val_split, x_test, y_test)

    def run_gb_model(self):
        x_train_split, x_val_split, y_train_split, y_val_split, x_test, y_test = self.load_and_preprocess_data()

        gb = GradientBoostingClassifier(loss='log_loss',
                                        learning_rate=0.095,
                                        n_estimators=95,
                                        subsample=1.0,
                                        criterion='friedman_mse',
                                        min_samples_split=2,
                                        min_samples_leaf=2,
                                        max_depth=3,
                                        random_state=42)
        gb.fit(x_train_split, y_train_split)

        self.evaluate_model(gb, x_val_split, y_val_split, x_test, y_test)

    def run_xgb_model(self):
        x_train_split, x_val_split, y_train_split, y_val_split, x_test, y_test = self.load_and_preprocess_data()

        xgboost = xgb.XGBClassifier(n_estimators=195,
                                    learning_rate=0.105,
                                    max_depth=4,
                                    subsample=0.8,
                                    colsample_bytree=0.8,
                                    reg_alpha=0.095,
                                    reg_lambda=1.0,
                                    random_state=42)
        xgboost.fit(x_train_split, y_train_split)

        self.evaluate_model(xgboost, x_val_split, y_val_split, x_test, y_test)

    def run_knn_model(self):
        x_train_split, x_val_split, y_train_split, y_val_split, x_test, y_test = self.load_and_preprocess_data()

        knn = KNeighborsClassifier(n_neighbors=5,
                                   weights='uniform',
                                   algorithm='auto',
                                   leaf_size=29,
                                   p=2,
                                   metric='minkowski')
        knn.fit(x_train_split, y_train_split)

        self.evaluate_model(knn, x_val_split, y_val_split, x_test, y_test)

if __name__ == "__main__":
    app = FraudDetectionApp()
    app.mainloop()