{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tkinter as tk\n",
        "from tkinter import filedialog\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "class FraudDetectionApp(tk.Tk):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.title(\"Fraud Detection App\")\n",
        "        self.geometry(\"600x400\")\n",
        "\n",
        "        self.train_label = tk.Label(self, text=\"Select Training Dataset:\")\n",
        "        self.train_label.pack(pady=10)\n",
        "\n",
        "        self.train_button = tk.Button(self, text=\"Select\", command=self.select_train_data)\n",
        "        self.train_button.pack()\n",
        "\n",
        "        self.test_label = tk.Label(self, text=\"Select Testing Dataset:\")\n",
        "        self.test_label.pack(pady=10)\n",
        "\n",
        "        self.test_button = tk.Button(self, text=\"Select\", command=self.select_test_data)\n",
        "        self.test_button.pack()\n",
        "\n",
        "        self.run_rf_button = tk.Button(self, text=\"Run Random Forest\", command=self.run_rf_model)\n",
        "        self.run_rf_button.pack()\n",
        "\n",
        "        self.run_gb_button = tk.Button(self, text=\"Run Gradient Boosting\", command=self.run_gb_model)\n",
        "        self.run_gb_button.pack()\n",
        "\n",
        "        self.run_xgb_button = tk.Button(self, text=\"Run XGBoost\", command=self.run_xgb_model)\n",
        "        self.run_xgb_button.pack()\n",
        "\n",
        "        self.run_knn_button = tk.Button(self, text=\"Run KNN\", command=self.run_knn_model)\n",
        "        self.run_knn_button.pack()\n",
        "\n",
        "        self.class_labels = [\"not fraud\", \"fraud\"]\n",
        "\n",
        "    def select_train_data(self):\n",
        "        self.train_file_path = filedialog.askopenfilename(title=\"Select Training Dataset\",\n",
        "                                                          filetypes=((\"CSV files\", \"*.csv\"),))\n",
        "        self.train_label.configure(text=f\"Selected Training Dataset: {self.train_file_path}\")\n",
        "\n",
        "    def select_test_data(self):\n",
        "        self.test_file_path = filedialog.askopenfilename(title=\"Select Testing Dataset\",\n",
        "                                                         filetypes=((\"Excel files\", \"*.xlsx\"),))\n",
        "        self.test_label.configure(text=f\"Selected Testing Dataset: {self.test_file_path}\")\n",
        "\n",
        "    def load_and_preprocess_data(self):\n",
        "        train_df = pd.read_csv(self.train_file_path)\n",
        "        test_df = pd.read_excel(self.test_file_path)\n",
        "\n",
        "        train_df.dropna(inplace=True)\n",
        "        test_df.dropna(inplace=True)\n",
        "\n",
        "        def engineer_features(df):\n",
        "            df['Time'] = pd.to_datetime(df['Time'])\n",
        "            df['Hour'] = df['Time'].dt.hour\n",
        "            df['DayOfWeek'] = df['Time'].dt.dayofweek\n",
        "\n",
        "            df_sorted = df.sort_values(by=['Card Number', 'Time'])\n",
        "            df_sorted['Time_Diff_Prev_Trans'] = df_sorted.groupby('Card Number')['Time'].diff().dt.total_seconds().fillna(0)\n",
        "            df_sorted['Amount_Diff_Avg'] = df_sorted['Amount'] - df_sorted.groupby('Card Number')['Amount'].transform('mean')\n",
        "            df_sorted['Transactions_Last_Hour'] = df_sorted.groupby('Card Number')['Time'].diff().lt(pd.Timedelta(hours=1)).astype(int).cumsum()\n",
        "            df_sorted['Amount_Diff_Median'] = df_sorted['Amount'] - df_sorted.groupby('Card Number')['Amount'].transform('median')\n",
        "\n",
        "            df = pd.concat([df, df_sorted[['Time_Diff_Prev_Trans', 'Amount_Diff_Avg', 'Transactions_Last_Hour', 'Amount_Diff_Median']]], axis=1)\n",
        "            return df\n",
        "\n",
        "        train_df = engineer_features(train_df)\n",
        "        test_df = engineer_features(test_df)\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        train_df['Amount'] = scaler.fit_transform(train_df[['Amount']])\n",
        "        test_df['Amount'] = scaler.transform(test_df[['Amount']])\n",
        "\n",
        "        columns_to_scale = ['Time_Diff_Prev_Trans', 'Transactions_Last_Hour']\n",
        "        train_df[columns_to_scale] = scaler.fit_transform(train_df[columns_to_scale])\n",
        "        test_df[columns_to_scale] = scaler.transform(test_df[columns_to_scale])\n",
        "\n",
        "        combined_df = pd.concat([train_df, test_df], axis=0)\n",
        "        lbl = LabelEncoder()\n",
        "        combined_df['merchant'] = lbl.fit_transform(combined_df['merchant'])\n",
        "        combined_df['category'] = lbl.fit_transform(combined_df['category'])\n",
        "\n",
        "        train_df = combined_df.iloc[:len(train_df)]\n",
        "        test_df = combined_df.iloc[len(train_df):]\n",
        "\n",
        "        fraud = train_df[train_df['is_fraud'] == 1]\n",
        "        legit = train_df[train_df['is_fraud'] == 0]\n",
        "\n",
        "        us_legit = legit.sample(n=500000, random_state=42)\n",
        "        us_train = pd.concat([fraud, us_legit])\n",
        "        us_train = us_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "        train_split = us_train[:450000]\n",
        "        val_split = us_train[450000:]\n",
        "        test_split = test_df.sample(n=50000, random_state=42)\n",
        "\n",
        "        features = ['Amount', 'merchant', 'category', 'Hour', 'DayOfWeek', 'Time_Diff_Prev_Trans', 'Transactions_Last_Hour', 'Amount_Diff_Median', 'Amount_Diff_Avg']\n",
        "        x_train_split = train_split[features]\n",
        "        y_train_split = train_split['is_fraud']\n",
        "        x_val_split = val_split[features]\n",
        "        y_val_split = val_split['is_fraud']\n",
        "        x_test = test_split[features]\n",
        "        y_test = test_split['is_fraud']\n",
        "\n",
        "        return x_train_split, x_val_split, y_train_split, y_val_split, x_test, y_test\n",
        "\n",
        "    def evaluate_model(self, model, x_val_split, y_val_split, x_test, y_test):\n",
        "        y_val_pred = model.predict(x_val_split)\n",
        "        y_test_pred = model.predict(x_test)\n",
        "\n",
        "        print(\"Validation Accuracy:\", accuracy_score(y_val_split, y_val_pred))\n",
        "        print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "        print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred, target_names=self.class_labels))\n",
        "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "        sns.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=self.class_labels, yticklabels=self.class_labels)\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Truth\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "\n",
        "    def run_rf_model(self):\n",
        "        x_train_split, x_val_split, y_train_split, y_val_split, x_test, y_test = self.load_and_preprocess_data()\n",
        "\n",
        "        rf = RandomForestClassifier(n_estimators=99,\n",
        "                                    criterion='gini',\n",
        "                                    min_samples_split=4,\n",
        "                                    min_samples_leaf=3,\n",
        "                                    random_state=42)\n",
        "        rf.fit(x_train_split, y_train_split)\n",
        "\n",
        "        self.evaluate_model(rf, x_val_split, y_val_split, x_test, y_test)\n",
        "\n",
        "    def run_gb_model(self):\n",
        "        x_train_split, x_val_split, y_train_split, y_val_split, x_test, y_test = self.load_and_preprocess_data()\n",
        "\n",
        "        gb = GradientBoostingClassifier(loss='log_loss',\n",
        "                                        learning_rate=0.095,\n",
        "                                        n_estimators=95,\n",
        "                                        subsample=1.0,\n",
        "                                        criterion='friedman_mse',\n",
        "                                        min_samples_split=2,\n",
        "                                        min_samples_leaf=2,\n",
        "                                        max_depth=3,\n",
        "                                        random_state=42)\n",
        "        gb.fit(x_train_split, y_train_split)\n",
        "\n",
        "        self.evaluate_model(gb, x_val_split, y_val_split, x_test, y_test)\n",
        "\n",
        "    def run_xgb_model(self):\n",
        "        x_train_split, x_val_split, y_train_split, y_val_split, x_test, y_test = self.load_and_preprocess_data()\n",
        "\n",
        "        xgboost = xgb.XGBClassifier(n_estimators=195,\n",
        "                                    learning_rate=0.105,\n",
        "                                    max_depth=4,\n",
        "                                    subsample=0.8,\n",
        "                                    colsample_bytree=0.8,\n",
        "                                    reg_alpha=0.095,\n",
        "                                    reg_lambda=1.0,\n",
        "                                    random_state=42)\n",
        "        xgboost.fit(x_train_split, y_train_split)\n",
        "\n",
        "        self.evaluate_model(xgboost, x_val_split, y_val_split, x_test, y_test)\n",
        "\n",
        "    def run_knn_model(self):\n",
        "        x_train_split, x_val_split, y_train_split, y_val_split, x_test, y_test = self.load_and_preprocess_data()\n",
        "\n",
        "        knn = KNeighborsClassifier(n_neighbors=5,\n",
        "                                   weights='uniform',\n",
        "                                   algorithm='auto',\n",
        "                                   leaf_size=29,\n",
        "                                   p=2,\n",
        "                                   metric='minkowski')\n",
        "        knn.fit(x_train_split, y_train_split)\n",
        "\n",
        "        self.evaluate_model(knn, x_val_split, y_val_split, x_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app = FraudDetectionApp()\n",
        "    app.mainloop()"
      ],
      "metadata": {
        "id": "fV-Kbwhd_hjL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}